{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7645184,"sourceType":"datasetVersion","datasetId":4456299},{"sourceId":163484245,"sourceType":"kernelVersion"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\nimport os\n\nzip_file_path = '/kaggle/input/pnd-14-256x256/train_patches.zip'\ntarget_folder = '/kaggle/working/train'\n\nif not os.path.exists(target_folder):\n    os.makedirs(target_folder)\n\n# Unzip the file\nwith zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n    zip_ref.extractall(target_folder)\n\nprint(f'Files extracted to {target_folder}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries imports\n\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\nfrom fastai.vision.all import *\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom sklearn.metrics import cohen_kappa_score, roc_auc_score, confusion_matrix\nfrom PIL import Image\nfrom fastai.metrics import Metric\nimport cv2\nimport matplotlib.pyplot as plt\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:45:14.7192Z","iopub.execute_input":"2024-02-20T00:45:14.71955Z","iopub.status.idle":"2024-02-20T00:45:21.494851Z","shell.execute_reply.started":"2024-02-20T00:45:14.719521Z","shell.execute_reply":"2024-02-20T00:45:21.493922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constants\npatch_size = 256  # Size of image patches\nbatch_size = 10  # Batch size\nn_patches = 14  # Number of patches per image\nTRAIN = '/kaggle/working/train'\nLABELS = '/kaggle/input/trainlabels/train.csv'\n\nmean = torch.tensor([0.803921, 0.596078, 0.729411])\nstd = torch.tensor([0.145098, 0.219607, 0.149019])\n\n# Calculate alphas based on class distribution\nclass_counts = [2893, 2666, 1344, 1243, 1250, 1225]\ntotal = sum(class_counts)\nalphas = [total / count for count in class_counts]\n\n# Normalize alphas\nalphas_sum = sum(alphas)\nnormalized_alphas = [alpha / alphas_sum for alpha in alphas]\nmin_alpha = min(normalized_alphas)\nscaled_alphas =  [alpha / min_alpha for alpha in normalized_alphas]","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:45:28.48556Z","iopub.execute_input":"2024-02-20T00:45:28.486775Z","iopub.status.idle":"2024-02-20T00:45:28.494937Z","shell.execute_reply.started":"2024-02-20T00:45:28.486732Z","shell.execute_reply":"2024-02-20T00:45:28.493764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preparation - Dataset definition\ndf = pd.read_csv(LABELS).set_index('image_id')\nfiles = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\ndf = df.loc[files].reset_index()\n\n# Separate a portion for evaluation\nrest_df, eval_df = train_test_split(df, test_size=0.1, stratify=df['isup_grade'], random_state=42)\nrest_df = rest_df.reset_index(drop=True)\neval_df = eval_df.reset_index(drop=True)\n\n# Train/Validation splitting\ntrain_df, valid_df = train_test_split(rest_df, test_size=0.15, stratify=rest_df['isup_grade'], random_state=42)\ntrain_df['split'] = 0\nvalid_df['split'] = 1\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\n\n\ndf_final = pd.concat([train_df, valid_df]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:45:31.942578Z","iopub.execute_input":"2024-02-20T00:45:31.943298Z","iopub.status.idle":"2024-02-20T00:45:32.166667Z","shell.execute_reply.started":"2024-02-20T00:45:31.943266Z","shell.execute_reply":"2024-02-20T00:45:32.165633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pre-processing, Dataloading\n\n# Get_x function to return image paths\ndef get_x(r):\n    return [Path(TRAIN)/f'{r[\"image_id\"]}_{i}.png' for i in range(n_patches)]\n\ndef get_y(r):\n    return r['isup_grade']\n\ndef open_images_eval(fn):\n    processed_imgs = []\n    for f in fn:\n        img = Image.open(f).convert('RGB')\n\n        # Dynamic padding - Normalization\n        padding = (0, 0, max(0, patch_size - img.width), max(0, patch_size - img.height))\n        tfms = transforms.Compose([\n            transforms.CenterCrop(patch_size),\n            transforms.Pad(padding, fill=(255, 255, 255), padding_mode='constant'),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n\n        img_tensor = tfms(img)\n        processed_imgs.append(img_tensor)\n\n    return processed_imgs\n\ndef open_images(fn):\n    processed_imgs = []\n    for f in fn:\n        img = Image.open(f).convert('RGB')\n\n        # Apply dynamic padding and transformations/normalization\n        tfms = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomVerticalFlip(),\n            transforms.CenterCrop(patch_size),\n            transforms.Pad((0, 0, max(0, patch_size - img.width), max(0, patch_size - img.height)), fill=(255, 255, 255), padding_mode='constant'),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n\n        img_tensor = tfms(img)\n        processed_imgs.append(img_tensor)\n\n    return processed_imgs\n\n\ndef collate(batch):\n    batch = [item for sublist in batch for item in sublist]  # Flatten the list of lists\n    batch = torch.stack(batch)\n    return batch\n\ndef custom_splitter():\n    def _inner(_):\n        train_idxs = df_final.index[df_final['split'] == 0].tolist()\n        valid_idxs = df_final.index[df_final['split'] == 1].tolist()\n        return train_idxs, valid_idxs\n    return _inner\n\n\n# DataLoaders (Training/Validation, Evaluation)\ndblock = DataBlock(\n    blocks=(TransformBlock(type_tfms=open_images), CategoryBlock),\n    get_x=get_x,\n    get_y=get_y,\n    splitter=custom_splitter(),\n    batch_tfms=[]\n)\n\ndls = dblock.dataloaders(df_final, bs=batch_size, collate_fn=collate)\n\ndblock_eval = DataBlock(blocks=(TransformBlock(type_tfms=open_images_eval), CategoryBlock),\n                        get_x=get_x,\n                        get_y=get_y,\n                        splitter=RandomSplitter(valid_pct=0))\ndls_eval = dblock_eval.dataloaders(eval_df, bs=batch_size, collate_fn=collate)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:45:36.368836Z","iopub.execute_input":"2024-02-20T00:45:36.369222Z","iopub.status.idle":"2024-02-20T00:45:38.083586Z","shell.execute_reply.started":"2024-02-20T00:45:36.369191Z","shell.execute_reply":"2024-02-20T00:45:38.082531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Select a Random Image\nrandom_index = random.randint(0, len(df_final)-1)\nrandom_image_row = df_final.iloc[random_index]\n\n#Load Image Patches\nimage_paths = get_x(random_image_row)  # Get paths for the patches\nimage_patches = open_images(image_paths)  # Load and preprocess patches\n\n#Plot the Patches\nfig, axes = plt.subplots(2, 7, figsize=(35, 10))  # Adjust the grid size\naxes = axes.flatten()\nfor i, img_tensor in enumerate(image_patches):\n    img = img_tensor.numpy().transpose((1, 2, 0))  # Convert tensor to numpy array and rearrange dimensions\n    img = img * std.numpy() + mean.numpy()  # Un-normalize using mean and std\n    img = np.clip(img, 0, 1)  # Clip values to be in the range [0, 1] for valid image display\n    axes[i].imshow(img)\n    axes[i].axis('off')\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:45:42.296451Z","iopub.execute_input":"2024-02-20T00:45:42.296952Z","iopub.status.idle":"2024-02-20T00:45:45.525256Z","shell.execute_reply.started":"2024-02-20T00:45:42.296914Z","shell.execute_reply":"2024-02-20T00:45:45.523972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\n\n# Mish activation function\nclass MishFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        x = ctx.saved_tensors[0]\n        sigmoid = torch.sigmoid(x)\n        tanh_sp = torch.tanh(F.softplus(x))\n        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n\nclass Mish(nn.Module):\n    def forward(self, x):\n        return MishFunction.apply(x)\n\ndef to_Mish(model):\n    for child_name, child in model.named_children():\n        if isinstance(child, nn.ReLU):\n            setattr(model, child_name, Mish())\n        else:\n            to_Mish(child)\n\n# N patches aggregator (into one unified map)\nclass PatchAggregator(nn.Module):\n    def __init__(self, in_features):\n        super().__init__()\n        self.aggregation = nn.Sequential(\n            nn.Linear(in_features, 128),\n            Mish(),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        weights = self.aggregation(x)\n        return (x * weights).sum(dim=1)\n\n# Pooling : Adaptive Average and Max\nclass Pooling(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.output_size = (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n    def forward(self, x):\n        return torch.cat([self.mp(x), self.ap(x)], 1)\n\n\n# Model Architecture\nclass DenseNetModel(nn.Module):\n    def __init__(self, n_classes=6):\n        super().__init__()\n        weights = DenseNet169_Weights.DEFAULT\n        base_model = densenet169(weights=weights)\n        layers = list(base_model.children())[:-1]\n        feature_dim = list(base_model.children())[-1].in_features\n        self.encoder = nn.Sequential(*layers)\n        self.pooling = Pooling()\n        self.aggregation = PatchAggregator(2 * feature_dim)\n        self.head = nn.Sequential(\n            nn.Linear(2 * feature_dim, 512),\n            nn.BatchNorm1d(512),\n            Mish(),\n            nn.Dropout(0.5),\n            nn.Linear(512, n_classes)\n        )\n\n    def forward(self, input):\n        n_patches = len(input)\n        batch_size, c, h, w = input[0].size()\n        stacked_patches = torch.stack(input,1).view(-1,c,h,w)\n        patch_features = self.encoder(stacked_patches)\n        reduced_features = self.pooling(patch_features).view(batch_size, n_patches, -1)\n        aggregated_features = self.aggregation(reduced_features)\n        return self.head(aggregated_features)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:46:00.938437Z","iopub.execute_input":"2024-02-20T00:46:00.938831Z","iopub.status.idle":"2024-02-20T00:46:00.956739Z","shell.execute_reply.started":"2024-02-20T00:46:00.938798Z","shell.execute_reply":"2024-02-20T00:46:00.955591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss function and metrics definition\n\n# Custom (weighted) Loss Function\nclass FocalLoss(nn.Module):\n    def __init__(self, alphas, gamma, reduction):\n        super().__init__()\n        self.gamma = gamma\n        self.reduction = reduction\n        self.alphas = torch.tensor(alphas).float()\n\n    def forward(self, inputs, targets):\n        alphas = self.alphas.to(inputs.device)\n\n        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        alpha = alphas[targets]\n        F_loss = alpha * ((1 - pt) ** self.gamma) * BCE_loss\n\n        if self.reduction == 'mean':\n            return torch.mean(F_loss)\n        elif self.reduction == 'sum':\n            return torch.sum(F_loss)\n        else:\n            return F_loss\n\n\n# Initialize the loss function with normalized alphas\nfocal_loss = FocalLoss(alphas=scaled_alphas, gamma=2, reduction='mean')\n\n# Metric Multiclass RocAuc\nclass MulticlassRocAuc(Metric):\n    def __init__(self):\n        self.preds = []\n        self.targets = []\n\n    def reset(self):\n        self.preds = []\n        self.targets = []\n\n    def accumulate(self, learn):\n        preds, targs = learn.pred, learn.y\n        self.preds.append(preds)\n        self.targets.append(targs)\n\n    @property\n    def value(self):\n        preds = torch.cat(self.preds)\n        targets = torch.cat(self.targets)\n        # Convert to one-hot format for multiclass ROC AUC calculation\n        targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=preds.size(-1))\n        return roc_auc_score(targets_one_hot.cpu().numpy(), preds.cpu().numpy(), multi_class='ovr')\n\nroc_auc_multiclass = MulticlassRocAuc()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:46:11.58178Z","iopub.execute_input":"2024-02-20T00:46:11.582752Z","iopub.status.idle":"2024-02-20T00:46:11.594533Z","shell.execute_reply.started":"2024-02-20T00:46:11.582708Z","shell.execute_reply":"2024-02-20T00:46:11.593482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learner definition and learning rate\n\n# Learner\nlearn = Learner(dls, DenseNetModel(), loss_func=focal_loss, opt_func=ranger, metrics=[roc_auc_multiclass, CohenKappa(weights='quadratic')])\n\nlearn.to_fp16()\n\n# Gradient Clipping\nlearn.clip_grad = 1.0\n\n# Find the optimal learning rate\nlearn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:46:15.685433Z","iopub.execute_input":"2024-02-20T00:46:15.686237Z","iopub.status.idle":"2024-02-20T00:48:01.527771Z","shell.execute_reply.started":"2024-02-20T00:46:15.686201Z","shell.execute_reply":"2024-02-20T00:48:01.526447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learner\nlearn = Learner(dls, DenseNetModel(), loss_func=focal_loss, opt_func=ranger, metrics=[CohenKappa(weights='quadratic')])\n\nlearn.to_fp16()\n\n# Gradient Clipping\nlearn.clip_grad = 1.0","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:49:08.602584Z","iopub.execute_input":"2024-02-20T00:49:08.603513Z","iopub.status.idle":"2024-02-20T00:49:09.028288Z","shell.execute_reply.started":"2024-02-20T00:49:08.603479Z","shell.execute_reply":"2024-02-20T00:49:09.027219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training and results [Over the validation set and on the evaluation set (unseen, unmasked images)]\n\n# Training\nlearn.fit_one_cycle(30, 0.0002290867705596611, cbs=[EarlyStoppingCallback(monitor='valid_loss', patience=24), SaveModelCallback(monitor='cohen_kappa_score', fname='best_model', with_opt=True)])\n\nlearn.load('best_model')\n\n# Generate predictions on the evaluation dataset\npreds, targs = learn.get_preds(dl=dls_eval.train)\n\n# Convert predictions to class indices\npred_classes = torch.argmax(preds, dim=1)\n\n# Calculate Kappa Score\nkappa_score = cohen_kappa_score(targs.numpy(), pred_classes.numpy(), weights='quadratic')\n\n# Calculate Confusion Matrix\nconf_matrix = confusion_matrix(targs.numpy(), pred_classes.numpy())\n\n# Convert softmax probabilities to class probabilities for each class\npreds_probs = F.softmax(preds, dim=1)\n\n# Convert targets to one-hot encoding to match the shape of preds_probs for ROC AUC calculation\ntargs_one_hot = F.one_hot(targs, num_classes=preds_probs.size(-1))\n\n# Calculate ROC AUC score for multiclass classification\nroc_auc = roc_auc_score(targs_one_hot.cpu().numpy(), preds_probs.cpu().numpy(), multi_class='ovr')\n\n# Output the results\nprint(f\"ROC AUC Score (Multiclass): {roc_auc}\")\nprint(f\"Kappa Score: {kappa_score}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:49:30.489483Z","iopub.execute_input":"2024-02-20T00:49:30.490014Z","iopub.status.idle":"2024-02-20T08:31:06.671005Z","shell.execute_reply.started":"2024-02-20T00:49:30.48998Z","shell.execute_reply":"2024-02-20T08:31:06.669734Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
